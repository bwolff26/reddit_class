{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e194cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that I'll likely re-visit all of these steps when I've collcted more data. However, for the present we'l start with this\n",
    "\n",
    "#I wonder if I should make a separate one for anime. I guess we'll find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10958172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c06e5020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(986, 6) (1010, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y'all Know What This Font Is? \\\\ Kagurabachi c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705890e+09</td>\n",
       "      <td>19cko5o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trying to find a manhwa/manhua but I cant reme...</td>\n",
       "      <td>I am trying to find a manga where the mc is a...</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705889e+09</td>\n",
       "      <td>19ckgrg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[DISC] Tower of God - Season 3 Episode 178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705889e+09</td>\n",
       "      <td>19ckf2s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ART] - Tatsuya Endo's illustration for Chapte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705888e+09</td>\n",
       "      <td>19ck611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is the artist from “sono mono nochi ni” the sa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705888e+09</td>\n",
       "      <td>19ck1j5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Y'all Know What This Font Is? \\\\ Kagurabachi c...   \n",
       "1  Trying to find a manhwa/manhua but I cant reme...   \n",
       "2         [DISC] Tower of God - Season 3 Episode 178   \n",
       "3  [ART] - Tatsuya Endo's illustration for Chapte...   \n",
       "4  Is the artist from “sono mono nochi ni” the sa...   \n",
       "\n",
       "                                            selftext  over_18 subreddit  \\\n",
       "0                                                NaN    False     manga   \n",
       "1   I am trying to find a manga where the mc is a...    False     manga   \n",
       "2                                                NaN    False     manga   \n",
       "3                                                NaN    False     manga   \n",
       "4                                                NaN    False     manga   \n",
       "\n",
       "           time       id  \n",
       "0  1.705890e+09  19cko5o  \n",
       "1  1.705889e+09  19ckgrg  \n",
       "2  1.705889e+09  19ckf2s  \n",
       "3  1.705888e+09  19ck611  \n",
       "4  1.705888e+09  19ck1j5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manga_table = pd.read_csv('data/manga_table_i.csv') #Starting with my initial two pulls.\n",
    "anime_table = pd.read_csv('data/anime_table_i.csv')\n",
    "print(manga_table.shape, anime_table.shape)\n",
    "manga_table.head() #On the topic: Future data I plan on also grabbing the flair. But for now...\n",
    "#Not that I even ended up using it - even in this current iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acd1eb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Having trouble finding Anime to watch with my ...</td>\n",
       "      <td>I started her with Death Note cause she loves ...</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705894e+09</td>\n",
       "      <td>19cm3ep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yuuki Bakuhatsu Bang Bravern (Bang Brave Bang ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705893e+09</td>\n",
       "      <td>19cls7i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>waifu 3x3. lets start a war!</td>\n",
       "      <td>[my 3x3 no order](https://imgur.com/a/nXsWUai)...</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705893e+09</td>\n",
       "      <td>19clr6w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>「Jaku-Chara Tomozaki-kun 2nd STAGE」WEB Preview...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705893e+09</td>\n",
       "      <td>19cln1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My Thoughts on season 1 of hibike euphonium.</td>\n",
       "      <td>These are my thoughts on season 1 without the ...</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705893e+09</td>\n",
       "      <td>19clmrv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Having trouble finding Anime to watch with my ...   \n",
       "1  Yuuki Bakuhatsu Bang Bravern (Bang Brave Bang ...   \n",
       "2                       waifu 3x3. lets start a war!   \n",
       "3  「Jaku-Chara Tomozaki-kun 2nd STAGE」WEB Preview...   \n",
       "4       My Thoughts on season 1 of hibike euphonium.   \n",
       "\n",
       "                                            selftext  over_18 subreddit  \\\n",
       "0  I started her with Death Note cause she loves ...    False     manga   \n",
       "1                                                NaN    False     manga   \n",
       "2  [my 3x3 no order](https://imgur.com/a/nXsWUai)...    False     manga   \n",
       "3                                                NaN    False     manga   \n",
       "4  These are my thoughts on season 1 without the ...    False     manga   \n",
       "\n",
       "           time       id  \n",
       "0  1.705894e+09  19cm3ep  \n",
       "1  1.705893e+09  19cls7i  \n",
       "2  1.705893e+09  19clr6w  \n",
       "3  1.705893e+09  19cln1f  \n",
       "4  1.705893e+09  19clmrv  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_table.head() #Oh, that's awkward.... must have messed up with my syntax when importing. \n",
    "#Anyways, that's obviously a mistake. Furthermore I base my mistaken on not only the first entry's title... but domain \n",
    "#knowldge with the fourth. Plus, I just googled the first one's id and it's in R/anime...\n",
    "\n",
    "#Sure enough, my current code, which I may change ONLY FOR THE SAKE OF CONDENSING my data pulling to one\n",
    "#'organized' document, has in it:'subreddit':my_subreddit_1, for the anime section, which was previously defined as\n",
    "#'my_subreddit_2'.... Gah... regardless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04a33b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note, on that topic is something quite interesting - the timing of things. Likely this is true for all matters and discussions,\n",
    "#but there is often a preference to discuss whatever is new. Perforce, with other data, albit not provided for us,\n",
    "#one could trace 'current events' to posts. Ie it makes a lot of sense for 'Jakua-Chara Tomozaki-kun'/'Bottom-tier\n",
    "#Tomozaki' to be discussed as the new anime season just came out two weeks ago. Now, likely that will bring with it\n",
    "#revived interest in the manga,but pragmatically....\n",
    "\n",
    "#And, on that topic: lower numbers are potentially more significant to animes as often the number of seasons with each one\n",
    "#are lower than the accompany 'comic-book' like format associated with manga [conversion rates vary, but for\n",
    "#an incredibly rough translation let's say 3ish (domain knowledge)]. Interestingly, a 2-gram might not pick this up as 'kun'\n",
    "#is a Japanese honorific for a younger male (generally), however 'Tomozaki-2nd', or the current 3-gram of\n",
    "#'Tomozaki-kun-2nd' would be significant.... however that is only imbuing with it domain knowledge - which the computer\n",
    "#does not have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9801fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Having trouble finding Anime to watch with my ...</td>\n",
       "      <td>I started her with Death Note cause she loves ...</td>\n",
       "      <td>False</td>\n",
       "      <td>anime</td>\n",
       "      <td>1.705894e+09</td>\n",
       "      <td>19cm3ep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yuuki Bakuhatsu Bang Bravern (Bang Brave Bang ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>anime</td>\n",
       "      <td>1.705893e+09</td>\n",
       "      <td>19cls7i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>waifu 3x3. lets start a war!</td>\n",
       "      <td>[my 3x3 no order](https://imgur.com/a/nXsWUai)...</td>\n",
       "      <td>False</td>\n",
       "      <td>anime</td>\n",
       "      <td>1.705893e+09</td>\n",
       "      <td>19clr6w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>「Jaku-Chara Tomozaki-kun 2nd STAGE」WEB Preview...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>anime</td>\n",
       "      <td>1.705893e+09</td>\n",
       "      <td>19cln1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My Thoughts on season 1 of hibike euphonium.</td>\n",
       "      <td>These are my thoughts on season 1 without the ...</td>\n",
       "      <td>False</td>\n",
       "      <td>anime</td>\n",
       "      <td>1.705893e+09</td>\n",
       "      <td>19clmrv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Having trouble finding Anime to watch with my ...   \n",
       "1  Yuuki Bakuhatsu Bang Bravern (Bang Brave Bang ...   \n",
       "2                       waifu 3x3. lets start a war!   \n",
       "3  「Jaku-Chara Tomozaki-kun 2nd STAGE」WEB Preview...   \n",
       "4       My Thoughts on season 1 of hibike euphonium.   \n",
       "\n",
       "                                            selftext  over_18 subreddit  \\\n",
       "0  I started her with Death Note cause she loves ...    False     anime   \n",
       "1                                                NaN    False     anime   \n",
       "2  [my 3x3 no order](https://imgur.com/a/nXsWUai)...    False     anime   \n",
       "3                                                NaN    False     anime   \n",
       "4  These are my thoughts on season 1 without the ...    False     anime   \n",
       "\n",
       "           time       id  \n",
       "0  1.705894e+09  19cm3ep  \n",
       "1  1.705893e+09  19cls7i  \n",
       "2  1.705893e+09  19clr6w  \n",
       "3  1.705893e+09  19cln1f  \n",
       "4  1.705893e+09  19clmrv  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_table['subreddit'] = 'anime'\n",
    "anime_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c08b9df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So yeah, just from the head we see two interesting things:\n",
    "#The first is 4/5 nans in just the selftext... likely those are pictures that we do not wish to explore for this\n",
    "#iteration of the project. We'll do a count momentarily.\n",
    "#Secondly, we already see a lot of Japanese.... besides the language gap, despite my experience, there will be not only\n",
    "#so many more stop words, but will likely be now so many more proper names, many of whom not capitalized, to make noise.\n",
    "#Thirdly, somewhat tangentially, will be spelling errors...\n",
    "#Fourthly will be the treatment of numbers... potentially relevant to certain things, likely in combination with things\n",
    "#ie episode... and alredy note in the third entry - we alrady have language that belongs to do 'anime' section seemingly...\n",
    "    #On the topic, we will need to be wary of emojis,etc... pragmatically we'll likely have enough data to just ignore them.\n",
    "\n",
    "#Pragmatically, we'll need to use Google translator a lot... for my sake and for the reader. But, for now, let us continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6844438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "selftext     538\n",
       "over_18        0\n",
       "subreddit      0\n",
       "time           0\n",
       "id             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manga_table.isnull().sum() #Thankfully just the self text... but wow... over half in manga's text are just imagines...\n",
    "#Yeah, at least in this subreddit very glad we'll be banking on the comments.\n",
    "\n",
    "#Tangential: Back in the day when I ran comments, apparently no nulls in the 10kish manga comments... perhaps only the\n",
    "#poster is able to make images and the like... I am unsure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ef02213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "selftext     155\n",
       "over_18        0\n",
       "subreddit      0\n",
       "time           0\n",
       "id             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_table.isnull().sum() #Oh, this is interesting - much less nulls in the anime section... Besides having more words\n",
    "#likely a difference in the two very similar things..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53979e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 7) (324, 7) (800, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(title          0\n",
       " flair        137\n",
       " selftext     162\n",
       " over_18        0\n",
       " subreddit      0\n",
       " time           0\n",
       " id             0\n",
       " dtype: int64,\n",
       " title          0\n",
       " flair        152\n",
       " selftext     167\n",
       " over_18        0\n",
       " subreddit      0\n",
       " time           0\n",
       " id             0\n",
       " dtype: int64,\n",
       " title          0\n",
       " flair          0\n",
       " selftext     120\n",
       " over_18        0\n",
       " subreddit      0\n",
       " time           0\n",
       " id             0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we'll start importing the second wave of Reddit day, gathered last night:\n",
    "mt2 = pd.read_csv('data/manga_table_ii.csv')\n",
    "mt3 = pd.read_csv('data/manga_table_iii.csv')\n",
    "at2 = pd.read_csv('data/anime_table_ii.csv')\n",
    "print(mt2.shape, mt3.shape, at2.shape) #Oh yes, recall that we added flair - so we'll add that to the initial merge...well, it'll\n",
    "#get accounted for later.\n",
    "mt2.isnull().sum(), mt3.isnull().sum(), at2.isnull().sum() #Unsurprisingly the trend of more nulls in manga..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27e907f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(992, 7) (963, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(title          0\n",
       " flair        440\n",
       " selftext     516\n",
       " over_18        0\n",
       " subreddit      0\n",
       " time           0\n",
       " id             0\n",
       " dtype: int64,\n",
       " title          0\n",
       " flair          0\n",
       " selftext     140\n",
       " over_18        0\n",
       " subreddit      0\n",
       " time           0\n",
       " id             0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Round III of extra tables:\n",
    "mt4 = pd.read_csv('data/manga_table_iv.csv')\n",
    "at4 = pd.read_csv('data/anime_table_iv.csv')\n",
    "print(mt4.shape, at4.shape)\n",
    "mt4.isnull().sum(), at4.isnull().sum() #Same trends as before. Nothing new to comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1885688c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 7) (965, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(title          0\n",
       " flair        385\n",
       " selftext     543\n",
       " over_18        0\n",
       " subreddit      0\n",
       " time           0\n",
       " id             0\n",
       " dtype: int64,\n",
       " title          0\n",
       " flair          0\n",
       " selftext     139\n",
       " over_18        0\n",
       " subreddit      0\n",
       " time           0\n",
       " id             0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Round IV of extra tables:\n",
    "mt5 = pd.read_csv('data/manga_table_v.csv')\n",
    "at5 = pd.read_csv('data/anime_table_v.csv')\n",
    "print(mt5.shape, at5.shape)\n",
    "mt5.isnull().sum(), at5.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46d1e3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(985, 7) (960, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(title          0\n",
       " flair        425\n",
       " selftext     524\n",
       " over_18        0\n",
       " subreddit      0\n",
       " time           0\n",
       " id             0\n",
       " dtype: int64,\n",
       " title          0\n",
       " flair          0\n",
       " selftext     131\n",
       " over_18        0\n",
       " subreddit      0\n",
       " time           0\n",
       " id             0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And, finally I hope we're done, round V:\n",
    "mt6 = pd.read_csv('data/manga_table_vi.csv')\n",
    "at6 = pd.read_csv('data/anime_table_vi.csv')\n",
    "print(mt6.shape, at6.shape)\n",
    "mt6.isnull().sum(), at6.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4829bd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(991, 7) (958, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(title          0\n",
       " flair        419\n",
       " selftext     531\n",
       " over_18        0\n",
       " subreddit      0\n",
       " time           0\n",
       " id             0\n",
       " dtype: int64,\n",
       " title          0\n",
       " flair          0\n",
       " selftext     128\n",
       " over_18        0\n",
       " subreddit      0\n",
       " time           0\n",
       " id             0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#...\n",
    "mt7 = pd.read_csv('data/manga_table_vii.csv')\n",
    "at7 = pd.read_csv('data/anime_table_vii.csv')\n",
    "print(mt7.shape, at7.shape)\n",
    "mt7.isnull().sum(), at7.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2127967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5555, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y'all Know What This Font Is? \\\\ Kagurabachi c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705890e+09</td>\n",
       "      <td>19cko5o</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trying to find a manhwa/manhua but I cant reme...</td>\n",
       "      <td>I am trying to find a manga where the mc is a...</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705889e+09</td>\n",
       "      <td>19ckgrg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[DISC] Tower of God - Season 3 Episode 178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705889e+09</td>\n",
       "      <td>19ckf2s</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ART] - Tatsuya Endo's illustration for Chapte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705888e+09</td>\n",
       "      <td>19ck611</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is the artist from “sono mono nochi ni” the sa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>manga</td>\n",
       "      <td>1.705888e+09</td>\n",
       "      <td>19ck1j5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Y'all Know What This Font Is? \\\\ Kagurabachi c...   \n",
       "1  Trying to find a manhwa/manhua but I cant reme...   \n",
       "2         [DISC] Tower of God - Season 3 Episode 178   \n",
       "3  [ART] - Tatsuya Endo's illustration for Chapte...   \n",
       "4  Is the artist from “sono mono nochi ni” the sa...   \n",
       "\n",
       "                                            selftext  over_18 subreddit  \\\n",
       "0                                                NaN    False     manga   \n",
       "1   I am trying to find a manga where the mc is a...    False     manga   \n",
       "2                                                NaN    False     manga   \n",
       "3                                                NaN    False     manga   \n",
       "4                                                NaN    False     manga   \n",
       "\n",
       "           time       id flair  \n",
       "0  1.705890e+09  19cko5o   NaN  \n",
       "1  1.705889e+09  19ckgrg   NaN  \n",
       "2  1.705889e+09  19ckf2s   NaN  \n",
       "3  1.705888e+09  19ck611   NaN  \n",
       "4  1.705888e+09  19ck1j5   NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Before we continue, let us confirm that we didn't mess up (again) on the data gathering and get\n",
    "#multiple rows or the like:\n",
    "#Given that I want to have an equal number of animes and mangas, we'll make them both seperate then combine:\n",
    "manga_lord = pd.concat([manga_table, mt2, mt3, mt4, mt5, mt6, mt7])\n",
    "manga_lord = manga_lord.reset_index(drop=True)\n",
    "print(manga_lord.shape)\n",
    "manga_lord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8e1fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4696, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Having trouble finding Anime to watch with my ...</td>\n",
       "      <td>I started her with Death Note cause she loves ...</td>\n",
       "      <td>False</td>\n",
       "      <td>anime</td>\n",
       "      <td>1.705894e+09</td>\n",
       "      <td>19cm3ep</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yuuki Bakuhatsu Bang Bravern (Bang Brave Bang ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>anime</td>\n",
       "      <td>1.705893e+09</td>\n",
       "      <td>19cls7i</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>waifu 3x3. lets start a war!</td>\n",
       "      <td>[my 3x3 no order](https://imgur.com/a/nXsWUai)...</td>\n",
       "      <td>False</td>\n",
       "      <td>anime</td>\n",
       "      <td>1.705893e+09</td>\n",
       "      <td>19clr6w</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>「Jaku-Chara Tomozaki-kun 2nd STAGE」WEB Preview...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>anime</td>\n",
       "      <td>1.705893e+09</td>\n",
       "      <td>19cln1f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My Thoughts on season 1 of hibike euphonium.</td>\n",
       "      <td>These are my thoughts on season 1 without the ...</td>\n",
       "      <td>False</td>\n",
       "      <td>anime</td>\n",
       "      <td>1.705893e+09</td>\n",
       "      <td>19clmrv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Having trouble finding Anime to watch with my ...   \n",
       "1  Yuuki Bakuhatsu Bang Bravern (Bang Brave Bang ...   \n",
       "2                       waifu 3x3. lets start a war!   \n",
       "3  「Jaku-Chara Tomozaki-kun 2nd STAGE」WEB Preview...   \n",
       "4       My Thoughts on season 1 of hibike euphonium.   \n",
       "\n",
       "                                            selftext  over_18 subreddit  \\\n",
       "0  I started her with Death Note cause she loves ...    False     anime   \n",
       "1                                                NaN    False     anime   \n",
       "2  [my 3x3 no order](https://imgur.com/a/nXsWUai)...    False     anime   \n",
       "3                                                NaN    False     anime   \n",
       "4  These are my thoughts on season 1 without the ...    False     anime   \n",
       "\n",
       "           time       id flair  \n",
       "0  1.705894e+09  19cm3ep   NaN  \n",
       "1  1.705893e+09  19cls7i   NaN  \n",
       "2  1.705893e+09  19clr6w   NaN  \n",
       "3  1.705893e+09  19cln1f   NaN  \n",
       "4  1.705893e+09  19clmrv   NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To build suspense, like they do in that medium, we'll make the anime first:\n",
    "anime_lord = pd.concat([anime_table, at2, at4, at5, at7])\n",
    "anime_lord = anime_lord.reset_index(drop=True)\n",
    "#anime_lord.drop(['index'], axis = 1)\n",
    "print(anime_lord.shape)\n",
    "anime_lord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a0efb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subreddit\n",
      "manga    711\n",
      "Name: count, dtype: int64\n",
      "subreddit\n",
      "anime    853\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Fine, let's do it, check for duplicates:\n",
    "print(manga_lord[manga_lord['id'].duplicated()]['subreddit'].value_counts())\n",
    "print(anime_lord[anime_lord['id'].duplicated()]['subreddit'].value_counts())\n",
    "#Oooh, that's tough to see... 782 duplicates.... Well, recall that we can still keep a unique value\n",
    "#from them, so we'd still probably have 3200... let's do just that.\n",
    "#Oh wait, I'm way overthinking this - let's just use unique...\n",
    "\n",
    "#Gah.... still a bit shy of manga; wait a bit longer and will be fine...\n",
    "#Anime, however,would still need two more pulls at the rate we'e going..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa25e537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4844\n",
      "3843\n"
     ]
    }
   ],
   "source": [
    "print(len(manga_lord['id'].unique())) #Per VII - finally good for manga, but one more good pull for anime... 647 more\n",
    "print(len(anime_lord['id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f68fce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4500-3843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3617997c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pausepause' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pausepause\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pausepause' is not defined"
     ]
    }
   ],
   "source": [
    "pausepause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3432fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(anime_lord['id'].unique()) #Oh, I guess the duplicated takes into account keeping at least\n",
    "#one of them... well, worth a try. Well, I want at least 3k, and might as well make it an\n",
    "#Even 3.5k....so guess we'll wait another week... well, at least do a bit more\n",
    "#progress tonight and spruce up the data gathering's formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_lord[anime_lord['id'].duplicated()].reset_index().iloc[0]['id'] #We'll focus on this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e9e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_lord[anime_lord['id']=='19bjifp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d201e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f61f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5760729d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aec8db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before we continue, let us confirm that we didn't mess up (again) on the data gathering and get\n",
    "#multiple rows or the like:\n",
    "df[df['id'].duplicated()]['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3a1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf6af91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e6288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that for the original two tables we did not yet have a flair column, which we will not be using for the first iteration\n",
    "#of this project. However, I'd like to go ahead and make it anyways [superfluos??]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ddc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's get an exactly even amount of of anime and manga. So, re. anime we will simply use the first 'n' rows from the second\n",
    "#dataset, assuming a normal distribution of post size.\n",
    "\n",
    "#Now that we also have at4, with the interesting case of manga being longer, we'll take all of anime 4 and supplement it with\n",
    "#with rest of anime 2. Reminder that the third round tables were compiled 1/31/24 - 10sih days later. We're still in the\n",
    "#mdidle of an anime season so we should be fine [another 8ish weeks for Winter 2024 anime; don't think such trends exist by\n",
    "#manga].\n",
    "animies_needed = manga_table.shape[0] + mt2.shape[0] + mt3.shape[0] + mt4.shape[0] - anime_table.shape[0] - at4.shape[0]\n",
    "animies_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc55ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So, we'll take the first 617 from the second anime table; eh, second and later iterations just use the variable name...\n",
    "at2 = at2.iloc[0:animies_needed]\n",
    "at2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b0792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anyways, we'll be adding the title to them all, so let's go ahead and combine them:\n",
    "df = pd.concat([manga_table, mt2, mt3, mt4, anime_table, at2, at4])\n",
    "df = df.reset_index(drop=True)\n",
    "#df.drop(['index'], axis = 1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['id'].duplicated()]['subreddit'].value_counts() #Gf me....I wonder if I went the wrong direction whenI was doing this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd31e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hmm.... so we have 2619 good mangas. We have whatevr number good animes - for simple math we have 2k....\n",
    "#So, we'll wait another 5 days at the moment before continuing... go fr 3k each..... gah.gf me. Honestly, could do it now\n",
    "#but on principal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2466c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mangmangmang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1186d0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44cf8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c8b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()  #Unsuprisingly high amounts of flair nulls, as we didn't correct them in our original data pulls.\n",
    "#Plus, the other two manga pulls had about 300 nulls for them. Regardless, for another iteration of this project it may\n",
    "#be useful to analyze flairs. Regardless, we continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cfa22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yeah, look below - while over half of the mangas are null, only 15% of animes are. See below.\n",
    "print(df[df['subreddit']=='manga']['selftext'].isnull().sum(), df[df['subreddit']=='manga']['selftext'].isnull().sum()/df[df['subreddit']=='manga']['selftext'].isnull().count())\n",
    "print(df[df['subreddit']=='anime']['selftext'].isnull().sum(), df[df['subreddit']=='anime']['selftext'].isnull().sum()/df[df['subreddit']=='anime']['selftext'].isnull().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bottom line, the current decision is to make a new column, joining together title, assuming significace in that (plus a way\n",
    "#to deal with all of those nulls...). Note that we will do this to all things, as all posts have a title [likly].\n",
    "#Pragmatically, when we later look at average word count, albeit not counting images and the like, we'd expect manga\n",
    "#to be less [a bit ironic considering it's the written version...].\n",
    "df = df.fillna(\"\")\n",
    "df['post'] = df['title'] + \" \" + df['selftext']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tangential to our current project, but I can't resist:\n",
    "df['over_18'] = df['over_18'].astype(int)\n",
    "print(df['over_18'].value_counts(normalize=True))\n",
    "print(df.groupby('subreddit')['over_18'].describe()) #Interestingly an almost 1:4 ratio between the two. Of also interest\n",
    "#is the general discrepency between images/text (see below after our basic post cleaning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ff1b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anyways, that reminds me to do the same integerizing to our subreddit:\n",
    "df['subreddit'] = df['subreddit'].map(dict(anime=1, manga=0))\n",
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c299be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b00a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I thought a lot about the following, but bottom line I insist on doing a bit of cleaning now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6f1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hmm, let's start by breaking apart the comments, trying to get an aveage word count...\n",
    "def document_words(raw_document):\n",
    "\n",
    "    #Remove some various html hiccups that may have crept in.\n",
    "    document_text = BeautifulSoup(raw_document).get_text()\n",
    "    \n",
    "    #Further purge it via regex to keep only characters per Regex. For sure in this case I'm keeping numbers\n",
    "    letters_only = re.sub(\"[^a-zA-Z0-9]\", \" \", document_text)\n",
    "    #Convert to lower case, split into individual words.\n",
    "    \n",
    "    #Re. lowercasing: I have a string feeling we'll be seeing a lot of acronyms, that will hopefully be capitalized.\n",
    "    #So, we'll leav this alone... Perhaps do some regex later/go back and rerunthis, but for at least an initial look...\n",
    "    #words = letters_only.lower().split()\n",
    "    #Note, that we've already alluded to potential concerns. re spelling - not only in Englsih but now we might have\n",
    "    #to be wary of Japanse spelling errors... Furthermore, potential misclassification via capitlzation discrepencies.\n",
    "    #Regardless... Oh, what we could do is make regex code for if it's just capital letters keep it... HMm... Yeah\n",
    "    #Let's do that.\n",
    "    \n",
    "    #Note, the regex I'd need should be as follows: /[A-Z]{2,}/gm... Yeah, this might get tricky with Regex... Let's\n",
    "    #make this simple and more user-friendly, albeit likely only a technical audience is reading all this:\n",
    "    \n",
    "    #Again, in retrospect maybe it would be recognizable...\n",
    "    #but in case a word's acrnoym is a stopword ie if 'FOR' means something... would otherwise get lost...\n",
    "    #Note, and likely redundant by now and the reader gets the point, but we'd still have to be wary of people lowercasing\n",
    "    #an acrnonym...\n",
    "    \n",
    "    #Note, the regex I'd need should be as follows: /[A-Z]{2,}/gm\n",
    "    \n",
    "    #The following should be what I want. Might even keep this for other cases...\n",
    "    \n",
    "    words = letters_only.split()\n",
    "    words = [w if w.isupper() else w.lower() for w in words]\n",
    "    \n",
    "    #AFTER, thinking about matters, I decided to leave stopwords to hyperparamter tuning, as perhaps certain\n",
    "    #eddits don't spell... For now we'll keep stemming though.\n",
    "    \n",
    "    #Removing stopwords per my default policy of keeping things simple. Note that we may need to go back\n",
    "    #to this and certain key English words in this domain might matter. Furthermore, we'll need to be wary of Japanese\n",
    "    #stop words. Ie we already see one in the first comments - 'Monster Musume no Iu Nichijou' translate to\n",
    "    #'Everyday Life with a Monster Girl' where 'no' in Japanese roughly translates to 'of', context dependent as we\n",
    "    #see already. In this example the two stop words would overlap. Pragmatically, there may be an example I'm not sure\n",
    "    #of, but you never know...\n",
    "    \n",
    "    #stops = set(stopwords.words('english'))#Note that I did see something about J. stop words.\n",
    "    #meaningful_words = [w for w in words if w not in stops]\n",
    "        #Hmm, I wonder if I should worry about 1 letter capital words... eh, at most 26... then I....\n",
    "    \n",
    "    #Stemming words... Hmm. Generally I am a big believer in stemming, but when dealing with another language I am\n",
    "    #a bit more hesitant. As a default we'll go with it.\n",
    "        #After completing the 'project' for the first time, in retrospect I think it would be important to experiment\n",
    "        #with not neccesarily stemming everything - especially when ultimately we deal with titles and have a much\n",
    "        #smaller base of words to experiment with, as opposed to the original ocean called posts.\n",
    "    p_stemmer = PorterStemmer()\n",
    "    stemmed_words = [p_stemmer.stem(i, to_lowercase=False) for i in words]\n",
    "    \n",
    "    #Note, that although it may proove worthwhile to lemmatize and retain more features, as lemmatization only lightly\n",
    "    #trims words, I prefer the more reductionalist result of stemming to cut down even more words to represent many.\n",
    "    \n",
    "    #And finally, let us merge back everything to a new document.\n",
    "    return(\" \".join(stemmed_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    " df['cleaned_post'] = df['post'].apply(document_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39abe92d",
   "metadata": {},
   "outputs": [],
   "source": [
    " df['cleaned_title'] = df['title'].apply(document_words) #With present time obligations, I doubt I will explore this, but\n",
    "#hopefully in the future. See below when we examine word length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f284d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['selftext'][1]) #Just doing a bit of a before and after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b333aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['post'][1]) #Remember that 'post' represents the 'complete' post of the user, combining their post's title and body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb247e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['cleaned_post'][1]) #Somewhat trimmed... Anyways, we'll go with this for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0887d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go time for word_counting\n",
    "df['word_count_post'] =  df['cleaned_post'].str.split().str.len()\n",
    "df['word_count_title'] =  df['cleaned_title'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c13e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7df8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count_post'].describe() #Very nice... I'm unsure what's typical, but this is looking well so far.\n",
    "#Notice something quite interesting: the mean is almost double the median! And, we can tell the max post is quite big...\n",
    "#a potential outlier to get rid of, but for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c554122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['word_count_post'] < 12]['subreddit'].value_counts(normalize=True)) #See below.\n",
    "print(len(df[df['word_count_post'] < 12]['subreddit']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec460a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('subreddit')['word_count_post'].describe() #Overall unsurprisingly given how many more nulls there were in\n",
    "#manga and pragmatically the main post would be longer than the title. Hence, the discrepency between\n",
    "#the medians - as the median manga's word count was only generated from its title!\n",
    "#Note that if you factor out the title and replace a picture [that's supposed to be worth a 'thousand words'] with 50-60\n",
    "#words, both the mean and median of manga posts approximate anime posts' length. Perhaps something true of all subreddits, or\n",
    "#at least these two domains... Regardless, we continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('subreddit')['word_count_title'].describe() #Now, see something far more even - on the sole basis of word\n",
    "#count in the titles [albeit after our scrubbing] the medians and third quadrants are the same. We have similar means and\n",
    "#first quartile values. Although we see greater values across the fields for animes, they are not so distant as we noticed\n",
    "#earlier with the \"posts\" which for manga was mostly relying on titles.\n",
    "\n",
    "#Also note the 'outliers' of both. Eh, look at the boxplot below to confirm visually, but considering how they both follow\n",
    "#such a trend I am completly unconcened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68452b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['selftext'] == '']['subreddit'].value_counts()  #So, for ultimately 867 of the mangas we are relying on their\n",
    "#titles; a mere 30ish percent of that is true for animes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdacf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I suppose before we start modeling we'll export our cleaned data [and also start working in a fresh notebook]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8228c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/cleaned_reddits.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b30b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the following is really from the EDA stage, I feel like I'll make the graphs for the word count post/titles here:\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax1 = plt.subplot(2,2,1)\n",
    "ax1.boxplot(df[df['subreddit'] ==0]['word_count_post'], showmeans=True)\n",
    "ax1.set_ylim(0, 200)\n",
    "ax1.set_title(\"Manga Post Word_Count\")\n",
    "\n",
    "ax2 = plt.subplot(2,2,2)\n",
    "ax2.boxplot(df[df['subreddit'] ==1]['word_count_post'], showmeans=True, patch_artist=True)\n",
    "ax2.set_ylim(0, 200)\n",
    "ax2.set_title(\"Anime Post Word_Count\")\n",
    "\n",
    "ax3 = plt.subplot(2,2,3)\n",
    "ax3.boxplot(df[df['subreddit'] ==0]['word_count_title'], showmeans=True)\n",
    "ax3.set_ylim(0, 50)\n",
    "ax3.set_title(\"Manga Title Word_Count\")\n",
    "\n",
    "ax4 = plt.subplot(2,2,4)\n",
    "ax4.boxplot(df[df['subreddit'] ==1]['word_count_title'], showmeans=True, patch_artist=True)\n",
    "ax4.set_ylim(0, 50)\n",
    "ax4.set_title(\"Anime Title Word_Count\")\n",
    "\n",
    "plt.tight_layout();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
